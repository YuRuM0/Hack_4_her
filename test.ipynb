{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b89ae123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "from docx import Document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4cd196d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin_df = df[mask]\n",
    "\t# filename = f\"women_{start:.1f}_to_{end:.1f}.csv\"\n",
    "\t# if not bin_df.empty:\n",
    "\t# \tbin_df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "628bd3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Job Description 100\n"
     ]
    }
   ],
   "source": [
    "doc = pd.read_csv('synthetic_vacancies_final.csv')\n",
    "\n",
    "df = pd.DataFrame(doc).iloc[99:199].sort_values('women_proportion')\n",
    "df = df.dropna(subset=['job_description', 'women_proportion'])\n",
    "print(\"Total Job Description\", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "08619107",
   "metadata": {},
   "outputs": [],
   "source": [
    "separated_dfs = {}\n",
    "\n",
    "for start in np.arange(0.0, 1.0, 0.1):\n",
    "\tend = start + 0.1\n",
    "\tmask = (df['women_proportion'] >= start) & (df['women_proportion'] < end)\n",
    "\tbin_df = df[mask]\n",
    "\tone_df = f\"{start:.1f}-{end:.1f}\"\n",
    "\tseparated_dfs[one_df] = bin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d877e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = df['women_proportion'].median() # gets the half\n",
    "# low_women = df[df['women_proportion'] <= threshold]\n",
    "# high_women = df[df['women_proportion'] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "304959f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print every 10%\n",
    "# for range_label, val in separated_dfs.items():\n",
    "# \tprint(f\"--- {range_label} ---\")\n",
    "# \tprint(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1db653dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: 0.0-0.1\n",
      "No text data available.\n",
      "========================================\n",
      "\n",
      "Group: 0.1-0.2\n",
      "No text data available.\n",
      "========================================\n",
      "\n",
      "Group: 0.2-0.3\n",
      "Top 10 words in the combined document:\n",
      "  role: 0.2393\n",
      "  high: 0.2025\n",
      "  security: 0.1964\n",
      "  work: 0.1780\n",
      "  analytical: 0.1780\n",
      "  experience: 0.1780\n",
      "  network: 0.1780\n",
      "  driven: 0.1595\n",
      "  technical: 0.1534\n",
      "  strong: 0.1534\n",
      "\n",
      "========================================\n",
      "\n",
      "Group: 0.3-0.4\n",
      "Top 10 words in the combined document:\n",
      "  role: 0.2807\n",
      "  work: 0.2532\n",
      "  high: 0.1871\n",
      "  data: 0.1816\n",
      "  network: 0.1706\n",
      "  strong: 0.1651\n",
      "  technical: 0.1596\n",
      "  experience: 0.1596\n",
      "  systems: 0.1486\n",
      "  position: 0.1321\n",
      "\n",
      "========================================\n",
      "\n",
      "Group: 0.4-0.5\n",
      "Top 10 words in the combined document:\n",
      "  work: 0.2845\n",
      "  skills: 0.2371\n",
      "  team: 0.2100\n",
      "  role: 0.1829\n",
      "  supportive: 0.1761\n",
      "  job: 0.1761\n",
      "  strong: 0.1761\n",
      "  analytical: 0.1693\n",
      "  data: 0.1626\n",
      "  technical: 0.1626\n",
      "\n",
      "========================================\n",
      "\n",
      "Group: 0.5-0.6\n",
      "Top 10 words in the combined document:\n",
      "  team: 0.3114\n",
      "  skills: 0.2401\n",
      "  strong: 0.2271\n",
      "  product: 0.2271\n",
      "  role: 0.1946\n",
      "  work: 0.1817\n",
      "  analytical: 0.1752\n",
      "  experience: 0.1622\n",
      "  technical: 0.1557\n",
      "  job: 0.1557\n",
      "\n",
      "========================================\n",
      "\n",
      "Group: 0.6-0.7\n",
      "Top 10 words in the combined document:\n",
      "  work: 0.3909\n",
      "  team: 0.2541\n",
      "  experience: 0.2280\n",
      "  strong: 0.2150\n",
      "  skills: 0.1889\n",
      "  role: 0.1824\n",
      "  cloud: 0.1629\n",
      "  communication: 0.1433\n",
      "  looking: 0.1433\n",
      "  requirements: 0.1368\n",
      "\n",
      "========================================\n",
      "\n",
      "Group: 0.7-0.8\n",
      "Top 10 words in the combined document:\n",
      "  work: 0.4081\n",
      "  team: 0.2597\n",
      "  skills: 0.2152\n",
      "  role: 0.2078\n",
      "  experience: 0.1929\n",
      "  strong: 0.1855\n",
      "  data: 0.1558\n",
      "  network: 0.1336\n",
      "  requirements: 0.1262\n",
      "  engineer: 0.1187\n",
      "\n",
      "========================================\n",
      "\n",
      "Group: 0.8-0.9\n",
      "No text data available.\n",
      "========================================\n",
      "\n",
      "Group: 0.9-1.0\n",
      "No text data available.\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_tfidf_words_single_doc(df, text_column, top_n=10):\n",
    "\timport numpy as np\n",
    "\tfrom sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\tcombined_text = \" \".join(df[text_column].astype(str).values)\n",
    "\tif not combined_text.strip():\n",
    "\t\tprint(\"No text data available.\\n\" + \"=\"*40 + \"\\n\")\n",
    "\t\treturn\n",
    "\n",
    "\tvectorizer = TfidfVectorizer(stop_words='english')\n",
    "\ttfidf_matrix = vectorizer.fit_transform([combined_text])\n",
    "\tfeature_names = vectorizer.get_feature_names_out()\n",
    "\trow_array = tfidf_matrix.toarray().flatten()\n",
    "\ttop_indices = np.argsort(row_array)[-top_n:][::-1]\n",
    "\ttop_words_scores = [(feature_names[i], row_array[i]) for i in top_indices]\n",
    "\n",
    "\tprint(f\"Top {top_n} words in the combined document:\")\n",
    "\tfor word, score in top_words_scores:\n",
    "\t\tprint(f\"  {word}: {score:.4f}\")\n",
    "\tprint(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "\n",
    "# Apply the function to each binned DataFrame\n",
    "for label, bin_df in separated_dfs.items():\n",
    "    print(f\"Group: {label}\")\n",
    "    print_top_tfidf_words_single_doc(bin_df, 'job_description')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
